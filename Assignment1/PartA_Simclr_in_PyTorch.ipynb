{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PartA - Simclr in PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c02730f0f13a426abcec461d5288a224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b7b01a0caca4dc1ae6c097b353e9a01",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_393c08b512e74c61bfffedd117b16cfa",
              "IPY_MODEL_652c8d11175f48ac91f5b2d8fe8737f2",
              "IPY_MODEL_9f9b3ad0d622412ba1da338621647e60"
            ]
          }
        },
        "9b7b01a0caca4dc1ae6c097b353e9a01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "393c08b512e74c61bfffedd117b16cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21327e658fb64d2ba10f6c1aad656470",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e5ef83a36fb472f9774fa75da5e27f8"
          }
        },
        "652c8d11175f48ac91f5b2d8fe8737f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_356e27b7e67e4f74aaac645d9cdd212e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1d53c6ee35346d7a463bfcc39889f9f"
          }
        },
        "9f9b3ad0d622412ba1da338621647e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9646f48615044342b65e6b98e345e5a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 50919877.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e75dec78467445118ab93118846c43e9"
          }
        },
        "21327e658fb64d2ba10f6c1aad656470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e5ef83a36fb472f9774fa75da5e27f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "356e27b7e67e4f74aaac645d9cdd212e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1d53c6ee35346d7a463bfcc39889f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9646f48615044342b65e6b98e345e5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e75dec78467445118ab93118846c43e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-RO4QG8EuvB"
      },
      "source": [
        "##SimCLR — A Simple Framework for Contrastive Learning of Visual Representations\n",
        "\n",
        "SimCLR uses contrastive learning to maximize agreement between 2 augmented versions of the same image.\n",
        "\n",
        "Steps\n",
        "\n",
        "1. Take an input image\n",
        "\n",
        "2. Prepare 2 random augmentations on the image\n",
        "\n",
        "3. Run a deep neural network like ResNet50 to obtain image embeddings of those augmented images.\n",
        "\n",
        "4. Run a small, fully connected linear neural network to project embeddings into another vector space.\n",
        "\n",
        "5. Calculate the contrastive loss and run backpropagation through both networks. Contrastive loss decreases when projections coming from the same image are similar. \n",
        "\n",
        "Reference: [https://arxiv.org/abs/2002.05709](https://arxiv.org/abs/2002.05709)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTfVn613L_sk"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3qshqfJESJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ea134f-f40f-47e5-be52-03b358bb910b"
      },
      "source": [
        "# Use wandb for logging\n",
        "!pip install --upgrade wandb --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 46.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGPvByEJMBIF"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZV98T_rEYXH"
      },
      "source": [
        "from dataclasses import asdict, dataclass\n",
        "from itertools import chain\n",
        "from pathlib import Path\n",
        "\n",
        "import hashlib\n",
        "import numpy as np\n",
        "from PIL.Image import Image\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10, CIFAR100\n",
        "from torchvision.models import resnet18, resnet34, resnet50\n",
        "from torchvision.transforms import (\n",
        "  ColorJitter, Compose, Lambda, Normalize, RandomApply, RandomGrayscale,\n",
        "  RandomHorizontalFlip, RandomResizedCrop, ToTensor)\n",
        "from tqdm import tqdm\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCTQo7wJMCnN"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5EcciTUEZAu"
      },
      "source": [
        "@dataclass(eq=True, frozen=True)\n",
        "class HParams:\n",
        "  cifar: int = 10\n",
        "  crop_size: int = 32\n",
        "  colour_distortion: int = 0.5\n",
        "  batch_size: int = 1024 # 256, 512, 1024, 2048, 4096 evaluated in paper\n",
        "  xent_temp: float = 0.5 # 0.1, 0.5, 1.0 evaluated in paper\n",
        "  proj_dim: int = 128\n",
        "  weight_decay: float = 1e-6\n",
        "  max_lr: float = 1.5 # 0.5, 1.0, 1.5 evaluated in paper\n",
        "  warmup_epochs: int = 10\n",
        "  cooldown_epochs: int = 90 # 90, 190, 290, 390, 490, 590, 690, 790, 890, 990 evaluated in paper\n",
        "  use_cosine_scheduler: bool = True\n",
        "  resnet_depth: int = 18 # 50 evaluated in paper\n",
        "  DEPTH_TO_REPR_DIM = {18: 512, 34: 512, 50: 2048}\n",
        "\n",
        "  def __post_init__(self):\n",
        "    assert self.cifar in (10, 100)\n",
        "    assert self.resnet_depth in self.DEPTH_TO_REPR_DIM\n",
        "  \n",
        "  @property\n",
        "  def repr_dim(self) -> int:\n",
        "    return self.DEPTH_TO_REPR_DIM[self.resnet_depth]\n",
        "\n",
        "  @property\n",
        "  def md5(self):\n",
        "    return hashlib.md5(str(hash(self)).encode('utf-8')).hexdigest()\n",
        "\n",
        "hp = HParams()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo5Nnu3CMFtM"
      },
      "source": [
        "## Image Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJzzBNCOEanZ"
      },
      "source": [
        "class SimCLRAugment(object):\n",
        "  def __init__(self, hp: HParams):\n",
        "    s = hp.colour_distortion\n",
        "    self.simclr_augment = Compose([\n",
        "      RandomResizedCrop(hp.crop_size),\n",
        "      RandomHorizontalFlip(),\n",
        "      RandomApply([\n",
        "        ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "      ], p=0.8),\n",
        "      RandomGrayscale(p=0.2),\n",
        "    ])\n",
        "\n",
        "  def __call__(self, img: Image):\n",
        "    aug = self.simclr_augment(img)\n",
        "    return (img, aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q78wi2PMJRN"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtb9uWk5EckD"
      },
      "source": [
        "def get_loaders(hp: HParams):\n",
        "  if hp.cifar == 10:\n",
        "    dataset = CIFAR10\n",
        "  elif hp.cifar == 100:\n",
        "    dataset = CIFAR100\n",
        "\n",
        "  train_transform = Compose([\n",
        "    SimCLRAugment(hp),\n",
        "    Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])),\n",
        "  ])\n",
        "  # Crops x Channels x Height x Width\n",
        "  train_dataset = dataset(\"./data\", train=True, transform=train_transform, download=True)\n",
        "\n",
        "  test_transform = ToTensor()\n",
        "  # Channels x Height x Width\n",
        "  test_dataset = dataset(\"./data\", train=False, transform=test_transform, download=True)\n",
        "\n",
        "  kwargs = {\"num_workers\": 1, \"pin_memory\": True}\n",
        "  train_loader = DataLoader(train_dataset, batch_size=hp.batch_size, shuffle=True, **kwargs)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=hp.batch_size, shuffle=False, **kwargs)\n",
        "  return train_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYVGPL0NMLFP"
      },
      "source": [
        "## Encoder and Projector Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KENee5c7Ed5u"
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, hp: HParams):\n",
        "    super().__init__()\n",
        "    if hp.resnet_depth == 18:\n",
        "      self.resnet = resnet18(pretrained=False, num_classes=hp.cifar)\n",
        "    elif hp.resnet_depth == 34:\n",
        "      self.resnet = resnet34(pretrained=False, num_classes=hp.cifar)\n",
        "    elif hp.resnet_depth == 50:\n",
        "      self.resnet = resnet50(pretrained=False, num_classes=hp.cifar)\n",
        "    self.resnet.conv1 = torch.nn.Conv2d(\n",
        "      3, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
        "    )\n",
        "    self.resnet.maxpool = torch.nn.Identity()\n",
        "    self.resnet.fc = torch.nn.Identity()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.resnet(x)\n",
        "\n",
        "class Projector(torch.nn.Module):\n",
        "  def __init__(self, hp: HParams):\n",
        "    super().__init__()\n",
        "    self.l1 = torch.nn.Linear(hp.repr_dim, hp.repr_dim)\n",
        "    self.l2 = torch.nn.Linear(hp.repr_dim, hp.proj_dim)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.l1(x))\n",
        "    return self.l2(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgt0WXnLMNkt"
      },
      "source": [
        "## Contrastive Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebQR9TTIEfcP"
      },
      "source": [
        "def nt_xent_loss(z: torch.Tensor, xent_temp: float):\n",
        "  # z: (N x 2) x projection_dim\n",
        "  N = z.shape[0] // 2 # Can be less than batch_size for last batch in epoch\n",
        "  znorm = z / torch.norm(z, 2, dim=1, keepdim=True)\n",
        "  cos_sim = torch.einsum('id,jd->ij', znorm, znorm) / xent_temp\n",
        "  cos_sim.fill_diagonal_(-1e5)\n",
        "  l = -F.log_softmax(cos_sim, 1)\n",
        "  idxs = np.arange(N)\n",
        "  return (l[2*idxs,2*idxs+1] + l[2*idxs+1,2*idxs]).sum() / (2*N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ9C4JtzMSfy"
      },
      "source": [
        "## Train Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcfrwBH7EiTg"
      },
      "source": [
        "def train(encoder, projector, train_loader, optimizer, epoch, xent_temp: float) -> None:\n",
        "  encoder.train()\n",
        "  projector.train()\n",
        "\n",
        "  batch_losses = []\n",
        "\n",
        "  for data, target in tqdm(train_loader, leave=False, desc=f'epoch {epoch}'):\n",
        "    bs, ncrops, c, h, w = data.size()\n",
        "    data = data.cuda()\n",
        "    target = target.cuda()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    z = projector(encoder(data.view((-1,c,h,w))))\n",
        "    loss = nt_xent_loss(z, xent_temp)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    batch_losses.append(loss.item())\n",
        "\n",
        "  wandb.log({\"Train Loss\": np.mean(batch_losses)}, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yrcGS_8MTvj"
      },
      "source": [
        "## Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB2PbcqwEkEJ"
      },
      "source": [
        "@torch.no_grad()\n",
        "def prepare_xy(encoder, loader):\n",
        "  encoder.eval()\n",
        "  projector.eval()\n",
        "\n",
        "  embeddings = []\n",
        "  for data, target in loader:\n",
        "    data = data.cuda()\n",
        "    if len(data.shape) == 5:\n",
        "      h = encoder(data[:,0,:,:,:])\n",
        "    else:\n",
        "      h = encoder(data)\n",
        "    embeddings.append((h.cpu().numpy(), target.numpy()))\n",
        "\n",
        "  X = np.concatenate([x[0] for x in embeddings])\n",
        "  y = np.concatenate([x[1] for x in embeddings])\n",
        "  return X, y\n",
        "\n",
        "def evaluate_logistic(X, y, Xt, yt, epoch: int) -> None:\n",
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "  Xt = scaler.transform(Xt)\n",
        "\n",
        "  clf = LogisticRegression(\n",
        "    random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=1000, n_jobs=1,\n",
        "  ).fit(X, y)\n",
        "  \n",
        "  results = {\n",
        "    'Train Evaluation': np.mean(clf.predict(X) == y),\n",
        "    'Test Evaluation': np.mean(clf.predict(Xt) == yt),\n",
        "  }\n",
        "  wandb.log(results, step=epoch)\n",
        "\n",
        "def evaluate_features(encoder, projector, train_loader, test_loader, epoch: int) -> None:\n",
        "  X, y = prepare_xy(encoder, train_loader)\n",
        "  Xt, yt = prepare_xy(encoder, test_loader)\n",
        "  evaluate_logistic(X, y, Xt, yt, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G96BQpgAMVmC"
      },
      "source": [
        "## Restore State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbJjiEDFEkrT"
      },
      "source": [
        "def save_state(hp, epoch: int, encoder, projector, optimizer, scheduler):\n",
        "  torch.save({\n",
        "    'hparams': hp,\n",
        "    'epoch': epoch,\n",
        "    'encoder_state_dict': encoder.state_dict(),\n",
        "    'projector_state_dict': projector.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scheduler_state_dict': scheduler.state_dict(),\n",
        "  }, hp.md5 + '.pkl')\n",
        "\n",
        "def load_state(hp):\n",
        "  try:\n",
        "    checkpoint = torch.load(hp.md5 + '.pkl')\n",
        "    return checkpoint\n",
        "  except FileNotFoundError:\n",
        "    return None\n",
        "\n",
        "checkpoint = load_state(hp)\n",
        "if checkpoint is not None:\n",
        "  print(f\"Restoring training state from epoch {checkpoint['epoch']}\")\n",
        "  hp = checkpoint['hparams']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdzWSAhcMY7p"
      },
      "source": [
        "## Instantiate State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuCUK40LEmBI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687,
          "referenced_widgets": [
            "c02730f0f13a426abcec461d5288a224",
            "9b7b01a0caca4dc1ae6c097b353e9a01",
            "393c08b512e74c61bfffedd117b16cfa",
            "652c8d11175f48ac91f5b2d8fe8737f2",
            "9f9b3ad0d622412ba1da338621647e60",
            "21327e658fb64d2ba10f6c1aad656470",
            "5e5ef83a36fb472f9774fa75da5e27f8",
            "356e27b7e67e4f74aaac645d9cdd212e",
            "a1d53c6ee35346d7a463bfcc39889f9f",
            "9646f48615044342b65e6b98e345e5a8",
            "e75dec78467445118ab93118846c43e9"
          ]
        },
        "outputId": "33b2a727-4840-4037-d32d-1ca861a5d267"
      },
      "source": [
        "torch.manual_seed(hash(hp))\n",
        "\n",
        "# Dataset\n",
        "train_loader, test_loader = get_loaders(hp)\n",
        "\n",
        "# Models\n",
        "encoder = Encoder(hp)\n",
        "projector = Projector(hp)\n",
        "if checkpoint is not None:\n",
        "  encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
        "  projector.load_state_dict(checkpoint['projector_state_dict'])\n",
        "encoder = encoder.cuda()\n",
        "projector = projector.cuda()\n",
        "\n",
        "# Optimizers and Schedulers\n",
        "init_lr = hp.max_lr / hp.warmup_epochs\n",
        "optimizer = SGD(chain(encoder.parameters(), projector.parameters()), lr=init_lr, weight_decay=1e-6)\n",
        "cosine_scheduler = CosineAnnealingLR(optimizer, hp.cooldown_epochs)\n",
        "if checkpoint is not None:\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  cosine_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "# Starting Epoch\n",
        "epoch = 1 if checkpoint is None else checkpoint['epoch']\n",
        "\n",
        "# Wandb\n",
        "wandb.init(anonymous='must')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c02730f0f13a426abcec461d5288a224",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">vibrant-shadow-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/pj123/uncategorized\" target=\"_blank\">https://wandb.ai/pj123/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/pj123/uncategorized/runs/2u0diovb\" target=\"_blank\">https://wandb.ai/pj123/uncategorized/runs/2u0diovb</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210919_223843-2u0diovb</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f423b584450>"
            ],
            "text/html": [
              "<h1>Run(2u0diovb)</h1><iframe src=\"https://wandb.ai/pj123/uncategorized/runs/2u0diovb\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RcGbVmVMaxg"
      },
      "source": [
        "## Train and Evaluation Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2oocJHJEniR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "outputId": "a20ada5d-5204-43a3-8c53-8a3e3ea7c287"
      },
      "source": [
        "%%wandb\n",
        "for epoch in range(epoch, hp.warmup_epochs + hp.cooldown_epochs + 1):\n",
        "  wandb.log({\"Learning Rate\": optimizer.param_groups[0]['lr']}, step=epoch)\n",
        "  train(encoder, projector, train_loader, optimizer, epoch, hp.xent_temp)\n",
        "  \n",
        "  if epoch <= hp.warmup_epochs:\n",
        "    optimizer.param_groups[0]['lr'] = min(hp.max_lr, hp.max_lr * (epoch+1)/10) # Pytorch LambdaLR scheduler is buggy...\n",
        "  elif hp.use_cosine_scheduler:\n",
        "    cosine_scheduler.step()\n",
        "  \n",
        "  if (epoch == 1) or (epoch % 10 == 0) or (epoch == hp.warmup_epochs + hp.cooldown_epochs):\n",
        "    evaluate_features(encoder, projector, train_loader, test_loader, epoch)\n",
        "    save_state(hp, epoch + 1, encoder, projector, optimizer, cosine_scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe src=\"https://wandb.ai/pj123/uncategorized/runs/2u0diovb?jupyter=true\" style=\"border:none;width:100%;height:420px\">\n",
              "                </iframe>"
            ],
            "text/plain": [
              "<wandb.jupyter.Run at 0x7f423deeed10>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "epoch 25:  76%|███████▌  | 37/49 [03:58<01:16,  6.40s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_be6HoGWVgk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}